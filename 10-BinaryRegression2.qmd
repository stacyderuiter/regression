
```{r, setup-binreg2, include=FALSE}
require(mosaic)   # Load additional packages here require(ggformula)
# Some customization.  You can alter or delete as desired (if you know what you are doing).
require(tidyverse)
require(ggformula)
theme_set(theme_bw(base_size=18))
knitr::opts_chunk$set(
  tidy=FALSE,     # display code as typed
  size="footnotesize",   # slightly smaller font for code
  fig.width=3.5, fig.height=2, fig.show='hold')
```
# Binary regression: Data with more than one trial per row
So far, the dataset we used for binary regression had one "trial" per row: there was a categorical variable in the dataset with two categories, "success" and "failure" (for the frogs: Abnormal and Normal). We wanted to estimate the probability of "success" as a function of several predictors.

If there are multiple trials that all have the same predictor-variable values, we can group them together into one row of data, and just record the number of "trials" and the number of "successes".  (From this, we can also get the number of "failures" = "trials" - "successes", if needed.) If we have a dataset that is stored in this format, we can still use `glm()` to fit a binary regression model.  The R code to fit the model changes just a bit, and we are able to do better model assessment a bit more easily.

An example follows.

## Data
The dataset used here is a reality-based simulated EIA dataset on duck sightings before and after windfarm installation (`impact`). Hourly, observers did up to 200 scans of the study area, and for each scan recorded whether duck(s) were seen (a success) or not (a failure).

The data file can be accessed online at:\\ \url{http://sldr.netlify.com/data/EIApropdata.csv}

```{r, duckdat, echo=FALSE, fig.width=6.5, fig.height=2.5}
pd <- read.csv('http://sldr.netlify.com/data/EIApropdata.csv')
head(pd,3)
```

## Checking the data setup
We would like to model the proportion scans with ducks sighted as a function of a set of covariates. Each row of our dataset gives us the number of successes in some number of trials (and also gives the corresponding values of the covariates for ALL those trials). We can also use this kind of summary data with a logistic regression; we will just need to add a column for the number of failures:

```{r}
pd <- pd %>% mutate(failures = trials-successes)
#or same thing in base R
pd$failures = pd$trials - pd$successes
```


## Fitting a saturated model
Let's try fitting a model for proportion sightings as a function of day, month, and impact. 

We need a response "variable" that is really 2 variables bound together: a column with the "successes" and a column with the "failures".  These don't have to be literally called successes and failures -- you can use whatever variable names you like -- but the first one of the two should be successes (the thing you want to compute the proportion for) and the second failures.

```{r, duck-lrm, echo=TRUE}
duck.logr <- glm( cbind(successes, failures) ~ day + month + impact, 
                  family=binomial(link='logit'),
                  data=pd)
summary(duck.logr)

#or maybe...
duck.logr2 <- glm( cbind(successes, failures) ~ day + factor(month) + impact, 
                   family=binomial(link='logit'), 
                   data=pd)
summary(duck.logr2)
```

## Checking linearity
What should be linear here? Well, `logit(p)` (where `p` is the probability of success, for a given set of predictor-variable values) should be a linear function of the predictors. *We can actually check this graphically now that we have multiple trials per row of data!* (But remember that the effects of other, unplotted predictors may also be influencing the plot that you see...)

Here, we need to decide: Do we see a linear pattern (or no pattern)? For the month and day data here, we might also consider whetehr it would make more sense to fit either of them as a categorical covariate rather than numeric.

```{r}
gf_point(logit(successes/trials) ~ day, data=pd) %>%
  gf_labs(y='logit(p)')
gf_point(logit(successes/trials) ~ month, data=pd)%>%
  gf_labs(y='logit(p)')
```

## Model Assessment
With data set up as proportions (many trials with the number of successes and failures in each row, rather than one row per trial), model assessment plots are a bit more useful. Specifically, we can check the Pearson residuals vs. fitted plot for constant variance as a function of fitted value, to confirm that the mean-variance relationship matches what we expect.

Since the Pearson residuals are already adjusted for the expected variance, we should see approximately constant spread, with values ranging from about -2 to 2 (and not more than a few larger than $\pm$ 3).

```{r}
acf(resid(duck.logr2, type='pearson'))
gf_point(resid(duck.logr2, type='pearson') ~ fitted(duck.logr2))
```

## Model Selection
We can do model selection as usual.
Here, it looks like the best model is the saturated (full) model.

```{r}
require(MuMIn)
duck.logr2 <- update(duck.logr2, na.action='na.fail')
dredge(duck.logr2)
```

We might also try using model selection to help us decide whether to use quantitative or categorical month and/or day...

```{r}
duck.logr2 <- update(duck.logr2, formula= . ~ . + month + factor(day), na.action='na.fail')
dredge(duck.logr2, rank='BIC')
```

Here it looks like day as quantitative and month as categorical works best.
